print(combined_vtec)
# Check if any data was combined before proceeding
if (nrow(combined_vtec) == 0) {
stop("No matching data points found between the two datasets after filtering by satellite and time. Cannot proceed.")
}
# 1. Define continuous sessions (segments) for each satellite. A new session
# begins after a data gap of more than 30 minutes.
time_gap_threshold_minutes <- 30
combined_vtec <- combined_vtec %>%
arrange(PRN, datetime) %>%
group_by(PRN) %>%
mutate(
# Calculate time difference from the previous measurement for this satellite
time_diff_internal = difftime(datetime, lag(datetime), units = "mins"),
# Create a segment ID. The ID increments for each new session.
# A new session starts at the first data point or after a significant time gap.
segment_id = cumsum(is.na(lag(datetime)) | time_diff_internal > time_gap_threshold_minutes)
) %>%
ungroup()
print(combined_vtec)
# 2. Calculate the bias for each session and apply it.
combined_vtec <- combined_vtec %>%
group_by(PRN, segment_id) %>%
mutate(
# For each session, calculate the single bias value
bias = mean(Vtec_TECGPS, na.rm = TRUE) - mean(Vtec_tecsuite, na.rm = TRUE),
# Adjust the Vtec_tecsuite by adding the calculated bias.
# This overwrites the original Vtec_tecsuite values.
Vtec_tecsuite = Vtec_tecsuite + bias
) %>%
ungroup() %>% # Ungroup to prevent accidental grouping in later steps
select(-bias, -time_diff_internal) # Clean up intermediate columns
print(combined_vtec)
# Create a directory to save the comparison plots.
output_dir <- paste0("comparison_vtec_absolutes_fitted", analysis_suffix)
if (!dir.exists(output_dir)) {
dir.create(output_dir)
}
# Get a list of unique satellites (PRNs) present in the combined data
unique_prns <- unique(combined_vtec$PRN)
# Loop through each satellite to create and save a plot
for (prn_to_plot in unique_prns) {
# Filter the data for the current satellite
# The 'segment_id' is already calculated for the entire dataset
satellite_data <- combined_vtec %>% filter(PRN == prn_to_plot)
# Reshape the data to a long format for easier plotting with ggplot2
# The 'segment_id' is carried over to the long format.
satellite_data_long <- satellite_data %>%
pivot_longer(cols = c(Vtec_tecsuite, Vtec_TECGPS),
names_to = "Source",
values_to = "VTEC")
# Create the plot
# The 'group' aesthetic now uses the pre-calculated 'segment_id' to correctly
# handle gaps in the data for both sources.
vtec_plot <- ggplot(satellite_data_long, aes(x = datetime, y = VTEC, color = Source, group = interaction(Source, segment_id))) +
geom_point(size = 1.5, alpha = 0.6) +
labs(
title = paste("VTEC Comparison for Satellite PRN", prn_to_plot, "(Bias Adjusted)"),
x = "Datetime (America/Anchorage)",
y = "VTEC (TECU)",
color = "VTEC Source"
) +
scale_color_manual(values = c("Vtec_tecsuite" = "blue", "Vtec_TECGPS" = "red")) +
scale_x_datetime(timezone = "America/Anchorage")
theme_minimal() +
theme(legend.position = "bottom")
# Define the filename and save the plot.
plot_filename <- file.path(output_dir, paste0("VTEC_comparison_fitted_PRN_", prn_to_plot, ".png"))
ggsave(plot_filename, plot = vtec_plot, width = 12, height = 6, dpi = 300, bg = "white")
}
print(combined_vtec)
# Calculate the average VTEC for each source across all satellites at each time point
# This uses the *adjusted* Vtec_tecsuite values
average_vtec <- combined_vtec %>%
group_by(datetime) %>%
summarise(
avg_Vtec_tecsuite = mean(Vtec_tecsuite, na.rm = TRUE),
avg_Vtec_TECGPS = mean(Vtec_TECGPS, na.rm = TRUE),
.groups = 'drop' # Drop grouping after summarising
)
print(combined_vtec)
# Reshape the averaged data to a long format for plotting
average_vtec_long <- average_vtec %>%
pivot_longer(
cols = c(avg_Vtec_tecsuite, avg_Vtec_TECGPS),
names_to = "Source",
values_to = "Average_VTEC"
)
print(average_vtec)
print(average_vtec_long)
print(average_vtec_segmented)
# Create segments to handle gaps in the time series data for the average plot
# This segmentation is for the *averaged* data, which may have different gaps
average_vtec_segmented <- average_vtec_long %>%
group_by(Source) %>%
arrange(datetime) %>%
mutate(
time_diff = difftime(datetime, lag(datetime), units = "mins"),
segment_id = cumsum(time_diff > time_gap_threshold_minutes | is.na(time_diff))
) %>%
ungroup()
print(average_vtec_segmented)
print(average_vtec_segmented)
# Create the plot for the averaged VTEC data
avg_vtec_plot <- ggplot(average_vtec_segmented, aes(x = datetime, y = Average_VTEC, color = Source, group = interaction(Source, segment_id))) +
geom_point(size = 1.5, alpha = 0.6) +
labs(
title = "Average VTEC Comparison (All Satellites, Bias Adjusted)",
x = "Datetime (America/Anchorage)",
y = "Average VTEC (TECU)",
color = "Average VTEC Source"
) +
scale_color_manual(
values = c("avg_Vtec_tecsuite" = "blue", "avg_Vtec_TECGPS" = "red"),
labels = c("avg_Vtec_tecsuite" = "Vtec_tecsuite (Avg, Adjusted)", "avg_Vtec_TECGPS" = "Vtec_TECGPS (Avg)")
) +
scale_x_datetime(date_labels = "%b %d\n%H:%M") +
theme_minimal() +
theme(legend.position = "bottom")
# Create the plot for the averaged VTEC data
avg_vtec_plot <- ggplot(average_vtec_segmented, aes(x = datetime, y = Average_VTEC, color = Source, group = interaction(Source, segment_id))) +
geom_point(size = 1.5, alpha = 0.6) +
labs(
title = "Average VTEC Comparison (All Satellites, Bias Adjusted)",
x = "Datetime (America/Anchorage)",
y = "Average VTEC (TECU)",
color = "Average VTEC Source"
) +
scale_color_manual(
values = c("avg_Vtec_tecsuite" = "blue", "avg_Vtec_TECGPS" = "red"),
labels = c("avg_Vtec_tecsuite" = "Vtec_tecsuite (Avg, Adjusted)", "avg_Vtec_TECGPS" = "Vtec_TECGPS (Avg)")
) +
theme_minimal() +
theme(legend.position = "bottom")
# Define the filename and save the average VTEC plot
avg_plot_filename <- file.path(output_dir, paste0("VTEC_average_comparison_fitted", analysis_suffix, ".png"))
ggsave(avg_plot_filename, plot = avg_vtec_plot, width = 12, height = 6, dpi = 300, bg = "white")
# Create the plot for the averaged VTEC data
avg_vtec_plot <- ggplot(average_vtec_segmented, aes(x = datetime, y = Average_VTEC, color = Source, group = interaction(Source, segment_id))) +
geom_point(size = 1.5, alpha = 0.6) +
labs(
title = "Average VTEC Comparison (All Satellites, Bias Adjusted)",
x = "Datetime (America/Anchorage)",
y = "Average VTEC (TECU)",
color = "Average VTEC Source"
) +
scale_color_manual(
values = c("avg_Vtec_tecsuite" = "blue", "avg_Vtec_TECGPS" = "red"),
labels = c("avg_Vtec_tecsuite" = "Vtec_tecsuite (Avg, Adjusted)", "avg_Vtec_TECGPS" = "Vtec_TECGPS (Avg)")
) +
scale_x_datetime(date_labels = "%b %d\n%H:%M", timezone = "America/Anchorage") +
theme_minimal() +
theme(legend.position = "bottom")
# Define the filename and save the average VTEC plot
avg_plot_filename <- file.path(output_dir, paste0("VTEC_average_comparison_fitted", analysis_suffix, ".png"))
ggsave(avg_plot_filename, plot = avg_vtec_plot, width = 12, height = 6, dpi = 300, bg = "white")
# Clear the environment
rm(list=ls())
# Load necessary libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(lubridate)
library(fuzzyjoin)
library(stringr)
library(readr)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
analysis_suffix <- "_only_valid_flat_bias"
#analysis_suffix <- "_included_invalid_flat_bias"
#analysis_suffix <- "_only_valid_dyn_bias"
#analysis_suffix <- "_included_invalid_dyn_bias"
# Load the datasets
gps_tec_raw <- read.table("data/gps-tec-output.Cmn", skip = 2, header = TRUE)
tec_suite_raw <- read_csv(paste0("data/tec_suite/tec_suite_vtec_data", analysis_suffix, ".csv"))
# Pre-process the first dataset (gps-tec)
gps_tec_raw$datetime <- as.POSIXct((gps_tec_raw$MJdatet) * 86400, origin = "1858-11-17", tz = "UTC")
# Pre-process the second dataset (tec_suite)
base_date <- as.Date(gps_tec_raw$datetime[1])
tec_suite_processed <- tec_suite_raw %>%
mutate(
datetime = as.POSIXct(base_date, tz = "UTC") + dhours(hour),
PRN = as.numeric(str_remove(satellite, "G")),
Vtec_tecsuite = vtec
) %>%
select(PRN, datetime, Vtec_tecsuite)
# Prepare the first dataset for merging
gps_tec <- gps_tec_raw %>%
rename(Vtec_TECGPS = Vtec) %>%
select(PRN, datetime, Vtec_TECGPS)
# 1. Get a list of satellites that appear in BOTH datasets
common_prns <- intersect(unique(tec_suite_processed$PRN), unique(gps_tec$PRN))
# 2. Initialize an empty list to store the joined data for each satellite
combined_vtec_list <- list()
# 3. Loop through each common satellite, join its data, and add to the list
for (current_prn in common_prns) {
# Filter data for the current satellite from both sources
tec_suite_subset <- tec_suite_processed %>% filter(PRN == current_prn)
gps_tec_subset <- gps_tec %>% filter(PRN == current_prn)
# Perform the fuzzy join ONLY on data for this specific satellite
joined_subset <- difference_inner_join(
tec_suite_subset,
gps_tec_subset,
by = "datetime",
max_dist = 2, # 2-second tolerance
distance_col = "time_diff"
)
# Add the result for this satellite to our list if any matches were found
if (nrow(joined_subset) > 0) {
combined_vtec_list[[as.character(current_prn)]] <- joined_subset
}
}
# 4. Combine all the individual data frames into one final data frame
combined_vtec <- bind_rows(combined_vtec_list) %>%
# Rename columns for clarity. PRN.x and PRN.y will be identical
# because we pre-filtered by satellite.
select(PRN = PRN.x, datetime = datetime.x, Vtec_tecsuite, Vtec_TECGPS)
print(combined_vtec)
combined_vtec <- combined_vtec %>%
# BEST PRACTICE: Convert the datetime object from UTC to the Alaskan time zone.
# This automatically handles the offset and daylight saving.
mutate(datetime = with_tz(force_tz(datetime, "UTC"), "America/Anchorage"))
# --- after the fuzzy join ------------------------------------------------------
combined_vtec <- bind_rows(combined_vtec_list) %>%                 # [1]
select(PRN = PRN.x, datetime = datetime.x,
Vtec_tecsuite, Vtec_TECGPS) %>%
# 1.  tag the current column as UTC
# 2.  convert it to Alaska time
# 3.  *if* the conversion rolled back a day, push it forward by 24 h
mutate(
datetime_UTC = force_tz(datetime, "UTC"),                      # keep a copy
datetime     = with_tz(datetime_UTC, "America/Anchorage"),     # -9 h
datetime     = if_else(                                        # loop-around
as.Date(datetime) < as.Date(datetime_UTC),                   # rolled back?
datetime + days(1),                                          # then +24 h
datetime)                                                    # else leave as-is
) %>%
select(-datetime_UTC)                                            # tidy up
print(combined_vtec)
# Check if any data was combined before proceeding
if (nrow(combined_vtec) == 0) {
stop("No matching data points found between the two datasets after filtering by satellite and time. Cannot proceed.")
}
# --- START: DYNAMIC BIAS ADJUSTMENT ---
# This section adjusts the 'Vtec_tecsuite' values.
# The goal is to match the mean of 'Vtec_tecsuite' to the mean of 'Vtec_TECGPS'
# for each continuous observation session of a satellite.
# 1. Define continuous sessions (segments) for each satellite. A new session
# begins after a data gap of more than 30 minutes.
time_gap_threshold_minutes <- 30
combined_vtec <- combined_vtec %>%
arrange(PRN, datetime) %>%
group_by(PRN) %>%
mutate(
# Calculate time difference from the previous measurement for this satellite
time_diff_internal = difftime(datetime, lag(datetime), units = "mins"),
# Create a segment ID. The ID increments for each new session.
# A new session starts at the first data point or after a significant time gap.
segment_id = cumsum(is.na(lag(datetime)) | time_diff_internal > time_gap_threshold_minutes)
) %>%
ungroup()
print(combined_vtec)
# 2. Calculate the bias for each session and apply it.
combined_vtec <- combined_vtec %>%
group_by(PRN, segment_id) %>%
mutate(
# For each session, calculate the single bias value
bias = mean(Vtec_TECGPS, na.rm = TRUE) - mean(Vtec_tecsuite, na.rm = TRUE),
# Adjust the Vtec_tecsuite by adding the calculated bias.
# This overwrites the original Vtec_tecsuite values.
Vtec_tecsuite = Vtec_tecsuite + bias
) %>%
ungroup() %>% # Ungroup to prevent accidental grouping in later steps
select(-bias, -time_diff_internal) # Clean up intermediate columns
# The 'combined_vtec' dataframe now contains the bias-adjusted 'Vtec_tecsuite' values,
# along with a 'segment_id' column that will be used for plotting.
# --- END: DYNAMIC BIAS ADJUSTMENT ---
# --- Plotting and Saving ---
# Create a directory to save the comparison plots.
output_dir <- paste0("comparison_vtec_absolutes_fitted", analysis_suffix)
if (!dir.exists(output_dir)) {
dir.create(output_dir)
}
# Get a list of unique satellites (PRNs) present in the combined data
unique_prns <- unique(combined_vtec$PRN)
# Loop through each satellite to create and save a plot
for (prn_to_plot in unique_prns) {
# Filter the data for the current satellite
# The 'segment_id' is already calculated for the entire dataset
satellite_data <- combined_vtec %>% filter(PRN == prn_to_plot)
# Reshape the data to a long format for easier plotting with ggplot2
# The 'segment_id' is carried over to the long format.
satellite_data_long <- satellite_data %>%
pivot_longer(cols = c(Vtec_tecsuite, Vtec_TECGPS),
names_to = "Source",
values_to = "VTEC")
# Create the plot
# The 'group' aesthetic now uses the pre-calculated 'segment_id' to correctly
# handle gaps in the data for both sources.
vtec_plot <- ggplot(satellite_data_long, aes(x = datetime, y = VTEC, color = Source, group = interaction(Source, segment_id))) +
geom_point(size = 1.5, alpha = 0.6) +
labs(
title = paste("VTEC Comparison for Satellite PRN", prn_to_plot, "(Bias Adjusted)"),
x = "Datetime (America/Anchorage)",
y = "VTEC (TECU)",
color = "VTEC Source"
) +
scale_color_manual(values = c("Vtec_tecsuite" = "blue", "Vtec_TECGPS" = "red")) +
scale_x_datetime(timezone = "America/Anchorage")
theme_minimal() +
theme(legend.position = "bottom")
# Define the filename and save the plot.
plot_filename <- file.path(output_dir, paste0("VTEC_comparison_fitted_PRN_", prn_to_plot, ".png"))
ggsave(plot_filename, plot = vtec_plot, width = 12, height = 6, dpi = 300, bg = "white")
}
print(combined_vtec)
# --- START: AVERAGE VTEC COMPARISON ---
# Calculate the average VTEC for each source across all satellites at each time point
# This uses the *adjusted* Vtec_tecsuite values
average_vtec <- combined_vtec %>%
group_by(datetime) %>%
summarise(
avg_Vtec_tecsuite = mean(Vtec_tecsuite, na.rm = TRUE),
avg_Vtec_TECGPS = mean(Vtec_TECGPS, na.rm = TRUE),
.groups = 'drop' # Drop grouping after summarising
)
print(average_vtec)
# Reshape the averaged data to a long format for plotting
average_vtec_long <- average_vtec %>%
pivot_longer(
cols = c(avg_Vtec_tecsuite, avg_Vtec_TECGPS),
names_to = "Source",
values_to = "Average_VTEC"
)
print(average_vtec_long)
# Create segments to handle gaps in the time series data for the average plot
# This segmentation is for the *averaged* data, which may have different gaps
average_vtec_segmented <- average_vtec_long %>%
group_by(Source) %>%
arrange(datetime) %>%
mutate(
time_diff = difftime(datetime, lag(datetime), units = "mins"),
segment_id = cumsum(time_diff > time_gap_threshold_minutes | is.na(time_diff))
) %>%
ungroup()
print(average_vtec_segmented)
# Create the plot for the averaged VTEC data
avg_vtec_plot <- ggplot(average_vtec_segmented, aes(x = datetime, y = Average_VTEC, color = Source, group = interaction(Source, segment_id))) +
geom_point(size = 1.5, alpha = 0.6) +
labs(
title = "Average VTEC Comparison (All Satellites, Bias Adjusted)",
x = "Datetime (America/Anchorage)",
y = "Average VTEC (TECU)",
color = "Average VTEC Source"
) +
scale_color_manual(
values = c("avg_Vtec_tecsuite" = "blue", "avg_Vtec_TECGPS" = "red"),
labels = c("avg_Vtec_tecsuite" = "Vtec_tecsuite (Avg, Adjusted)", "avg_Vtec_TECGPS" = "Vtec_TECGPS (Avg)")
) +
scale_x_datetime(date_labels = "%b %d\n%H:%M", timezone = "America/Anchorage") +
theme_minimal() +
theme(legend.position = "bottom")
# Define the filename and save the average VTEC plot
avg_plot_filename <- file.path(output_dir, paste0("VTEC_average_comparison_fitted", analysis_suffix, ".png"))
ggsave(avg_plot_filename, plot = avg_vtec_plot, width = 12, height = 6, dpi = 300, bg = "white")
# --- END: AVERAGE VTEC COMPARISON ---
print("--- Script finished successfully! All plots have been saved. ---")
# Clear the environment
rm(list=ls())
# Load necessary libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(nortest)
library(lubridate)
library(fuzzyjoin)
library(purrr)
library(stringr)
library(readr) # Added readr for read_csv
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
gps_tec_raw <- read.table("data/gps-tec-output.Cmn", skip = 2, header = TRUE) %>%
mutate(datetime = as.POSIXct((MJdatet) * 86400, origin = "1858-11-17", tz = "UTC"))
analysis_suffix <- "_only_valid_flat_bias"
#analysis_suffix <- "_included_invalid_flat_bias"
#analysis_suffix <- "_only_valid_dyn_bias"
#analysis_suffix <- "_included_invalid_dyn_bias"
#tec_suite_raw <- read_csv("data/tec_suite/tec_suite_vtec_data.csv")
tec_suite_raw <- read_csv(paste0("data/tec_suite/tec_suite_vtec_data", analysis_suffix, ".csv"))
base_date <- as.Date(gps_tec_raw$datetime[1]) # Use the date from the GPS data as the base
gps_tec_processed <- gps_tec_raw %>%
rename(Vtec_TECGPS = Vtec) %>%
select(PRN, datetime, Vtec_TECGPS)
tec_suite_processed <- tec_suite_raw %>%
mutate(
datetime = as.POSIXct(base_date) + dhours(hour),
PRN = as.numeric(str_remove(satellite, "G")),
Vtec_tecsuite = vtec # In the new file, 'vtec' is the column we need
) %>%
select(PRN, datetime, Vtec_tecsuite)
common_prns <- intersect(unique(gps_tec_processed$PRN), unique(tec_suite_processed$PRN))
# Use purrr::map_dfr for a concise way to loop, join, and row-bind results
all_residuals <- map_dfr(common_prns, function(current_prn) {
# Filter data for the current satellite from both sources
gps_subset <- gps_tec_processed %>% filter(PRN == current_prn)
tec_suite_subset <- tec_suite_processed %>% filter(PRN == current_prn)
# Perform the fuzzy join on the single-satellite subsets
difference_inner_join(
gps_subset,
tec_suite_subset,
by = "datetime",
max_dist = 2, # 2-second tolerance
distance_col = "time_diff"
) %>%
# Calculate residuals and select final columns immediately
mutate(
r_t = Vtec_tecsuite - Vtec_TECGPS
) %>%
select(
PRN = PRN.x, # PRN.x and PRN.y are the same here
datetime = datetime.x,
Vtec_tecsuite,
Vtec_TECGPS,
r_t
)
})
# --- MODIFICATION END ---
# --- The rest of the script requires no changes as it works on 'all_residuals' ---
# Check if any residuals were calculated
if (nrow(all_residuals) == 0) {
stop("No matching data points found between the two sources. Cannot continue with analysis.")
}
# Descriptive Statistics per PRN
stats_per_prn <- all_residuals %>%
group_by(PRN) %>%
summarise(n = n(),
min = min(r_t, na.rm = TRUE),
Q1 = quantile(r_t, 0.25, na.rm = TRUE),
median = median(r_t, na.rm = TRUE),
Q3 = quantile(r_t, 0.75, na.rm = TRUE),
max = max(r_t, na.rm = TRUE),
mean = mean(r_t, na.rm = TRUE),
variance = var(r_t, na.rm = TRUE),
.groups = 'drop')
print("--- Descriptive Statistics per PRN ---")
print(stats_per_prn)
# Normality test (Shapiro-Wilk) per PRN
normality_tests <- all_residuals %>%
group_by(PRN) %>%
# Use a sample if N > 5000, as shapiro.test has a limit
summarise(p_value = {
data_sample <- if(n() > 4999) sample(r_t, 4999) else r_t
tryCatch(shapiro.test(data_sample)$p.value, error = function(e) NA)
},
.groups = 'drop')
print("--- Shapiro-Wilk Normality Test P-Values per PRN ---")
print(normality_tests)
# Global Statistics (all PRNs combined)
global_stats <- all_residuals %>%
summarise(n = n(),
min = min(r_t, na.rm = TRUE),
Q1 = quantile(r_t, 0.25, na.rm = TRUE),
median = median(r_t, na.rm = TRUE),
Q3 = quantile(r_t, 0.75, na.rm = TRUE),
max = max(r_t, na.rm = TRUE),
mean = mean(r_t, na.rm = TRUE),
variance = var(r_t, na.rm = TRUE))
print("--- Global Statistics Across All PRNs ---")
print(global_stats)
# Global Normality Test (Anderson-Darling is better for large samples)
print("--- Global Anderson-Darling Normality Test ---")
global_normality_ad <- nortest::ad.test(all_residuals$r_t)
print(global_normality_ad)
# Visualization for Each PRN
# Directory to save plots
output_dir <- paste0("plots_residuals", analysis_suffix)
dir.create(output_dir, showWarnings = FALSE)
# Generate and save a plot for each PRN
unique_prns <- unique(all_residuals$PRN)
for (prn in unique_prns) {
res_subset <- all_residuals %>% filter(PRN == prn)
p1 <- ggplot(res_subset, aes(x = r_t)) +
geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", alpha = 0.6) +
geom_density(color = "red", size = 1) +
labs(title = paste("Histogram + Density for Residuals, PRN", prn),
x = "Residual (r_t = Vtec_tecsuite - Vtec_TECGPS)", y = "Density") +
theme_minimal()
p2 <- ggplot(res_subset, aes(y = r_t)) +
geom_boxplot(fill = "lightgreen", alpha = 0.6) +
labs(title = paste("Boxplot of Residuals, PRN", prn), y = "Residual (r_t)") +
theme_minimal()
filename1 <- file.path(output_dir, paste0("histogram_residuals_PRN_", prn, ".png"))
ggsave(filename1, plot = p1, width = 10, height = 6, dpi = 300, bg = "white")
filename2 <- file.path(output_dir, paste0("boxplot_residuals_PRN_", prn, ".png"))
ggsave(filename2, plot = p2, width = 6, height = 6, dpi = 300, bg = "white")
}
# Global Density Plot
global_hist_plot <- ggplot(all_residuals, aes(x = r_t)) +
geom_histogram(aes(y = ..density..), bins = 50, fill = "skyblue", alpha = 0.5) +
geom_density(color = "darkred", size = 1) +
labs(title = "Global Residuals Density Across All PRNs", x = "Residual (r_t)", y = "Density") +
theme_minimal()
ggsave(file.path(output_dir, "histogram_residuals_GLOBAL.png"), plot = global_hist_plot, width = 10, height = 6, dpi = 300, bg = "white")
# Global Time Series Plot
global_ts_plot <- ggplot(all_residuals, aes(x = datetime, y = r_t, color = factor(PRN))) +
geom_point(alpha = 0.4, size = 1) +
labs(title = "Residuals Over Time for All PRNs",
x = "Datetime", y = "Residual (r_t)",
color = "PRN") +
theme_minimal()
ggsave(file.path(output_dir, "timeseries_residuals_GLOBAL.png"), plot = global_ts_plot, width = 12, height = 7, dpi = 300, bg = "white")
# Save master residuals table
write.csv(all_residuals, "all_residuals.csv", row.names = FALSE)
print(paste("--- Script finished successfully! All plots saved in '", output_dir, "' directory. ---"))
